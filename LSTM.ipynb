{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/joelleng/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/joelleng/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/joelleng/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/joelleng/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import for database connection and other basic libraries\n",
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Import libraries for LSTM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to data warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwh_host = os.getenv(\"DATAWH_ENDPOINT\")\n",
    "dwh_user = os.getenv(\"DATAWH_USERNAME\")\n",
    "dwh_pw = os.getenv(\"DATAWH_PASSWORD\")\n",
    "dwh_name = os.getenv(\"DATAWH_NAME\")\n",
    "dwh_port = os.getenv(\"DATAWH_PORT\")\n",
    "\n",
    "# db_datawarehouse = mysql.connector.connect(\n",
    "#     host=dwh_host,\n",
    "#     user=dwh_user,\n",
    "#     passwd=dwh_pw,\n",
    "#     database=dwh_name\n",
    "# )\n",
    "\n",
    "engine = create_engine(f'mysql://{dwh_user}:{dwh_pw}@{dwh_host}:{dwh_port}/{dwh_name}', echo=False, future=True)\n",
    "db_datawarehouse = engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up for LSTM\n",
    "1) CUDA usage\n",
    "2) Load dataset and to train test split\n",
    "    - Utilise the temporal dimension of our data to conduct dataset splot, we will split it into 80/10/10 of train set, test set and val set respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_table('review', db_datawarehouse).copy()\n",
    "df = df.drop(columns=['index'])\n",
    "#print([data['Rating'].value_counts(), data['Text_Sentiment'].value_counts(), data['Title_Sentiment'].value_counts()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data is (10045,) and (10045,)\n",
      "Shape of test data is (593,) and (593,)\n",
      "Shape of val data is (594,) and (594,)\n"
     ]
    }
   ],
   "source": [
    "data = df[['ReviewText', 'DateOfStay', 'Text_Sentiment']]\n",
    "train_data = data[data['DateOfStay'].apply(lambda x: int(x.split('-')[0])) < 2022]\n",
    "test_data = data[data['DateOfStay'].apply(lambda x: int(x.split('-')[0])) >= 2022]\n",
    "X_trainset, y_trainset = train_data['ReviewText'].values, train_data['Text_Sentiment'].values\n",
    "X_test_val, y_test_val = test_data['ReviewText'].values, test_data['Text_Sentiment'].values\n",
    "X_testset, X_valset, y_testset, y_valset = train_test_split(X_test_val, y_test_val, test_size=0.5)\n",
    "\n",
    "print(f'Shape of train data is {X_trainset.shape} and {y_trainset.shape}')\n",
    "print(f'Shape of test data is {X_testset.shape} and {y_testset.shape}')\n",
    "print(f'Shape of val data is {X_valset.shape} and {y_valset.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Text input: Due to the pandemic and the fluid nature of border restrictions, we opted to spend our anniversary this year in Singapore again.      We opted for 3 separate staycations and, in order to compare the hotels we 've chosen, the duration for each of our staycations was the same duration and over the same days of different weeks.    Marina Bay Sands was our second staycation.    We had stayed once before but that memory was become fuzzy.  All I could remember was that the restroom was huge.    Actually we didn 't plan to stay at the MBS.  However, due to the availability of a promotion, we decided to have our second staycation there  u2013 and boy were we glad we did.    We always opt for rooms with club benefits.  However, during the period of our staycation, all the rooms with club access were under renovation and only suites were available.  I decided against going for a suite since we would probably just stay on bed the whole time and would not be able to justify the hefty costs for the extra space in the suite.    Hence, it was with trepidation that we booked for our stay from December 14 to 16 2021.      My wife was so apprehensive about the prospect of a staycation without club benefits that she wanted to cancel it.     Pros:  1.  MBS makes full use of technology.  Prior to our check-in, we received a link to select our preferred check-in time.  This totally removed the need to speak with the front desk at the start of our staycation.  We also got to book our slots for the use of the infinity pools and other hotel facilities.     2.  The hotel is really serious about its safe management measures.  This is the ONLY hotel that checks in every guest who uses the lifts to the room and checks out every guest who exits the lifts.  There is no way extra  'guests ' can make their way into the guest rooms.    3.  The air-con in the room works fantastically well.  The room was chilled to the level of our liking!     4. Although we stayed in an ordinary room, the mini bar was replenished daily and it was free!  What a treat!     5.  I have always thought that having a TV in the room was a silly idea.  However, MBS managed to change that opinion of mine because its smart TV was easy to connect to my phone and we could watch Netflix on TV.    I have stayed in hotels that have smart TVs that are impossible to connect.   Staying at the MBS was like staying at home  u2013 only better.    6.  My initial thought that the check-in process was one that was going to spoil my staycation due to the sheer number of people at the lobby.  However my personal experience was a super pleasant one.  I was ushered into a room with a seat and was attended to by a very thorough and professional Ms Adilah.  Ms Adilah did not ask questions as a filler or just to make small talk.  She asked questions so that she could provide solutions.  For example, she asked if I have booked for my pool sessions.  When I told her I could not get a timing for the first day, she took the trouble to secure a slot after making a few checks.    To me, the checking in process sets the tone for my stay.    Thank you, Ms Adilah!        7.  There are a lot to do at the Marina Shoppes.  Because my membership was upgraded to the next tier, it made shopping and dinning at the restaurants linked via the escalators an even better experience.    8.  Checking out was equally efficient.  No forms.  No queues.  Just drop your room card and its done.    Cons:    Normally I would have a long list of cons.  For MBS, the ONLY negative point I would give was for our unfortunate dinner experience at the Rise Restaurant located in the lobby.    Not only was the waiting time for our food unduly long, the taste way of the fried rice and satay were below mediocre.  I really don 't think the restaurant can justify the 40-minute waiting time for a plate of fried rice and a few sticks of satay.     Moreover, our order of satay came undercooked!      The mutton was impossible to chew and the meat was red and bloody.  I had to spit it out.     When I informed the wait staff, the remaining 2 sticks of satay were sent back to the kitchen and returned  - charred and inedible.    On hindsight, I thought even a regular restaurant would have prepared another 2-3 sticks of satay and served them to us instead of taking the undercooked ones back into the kitchen to char them.    Given the current pandemic situation, I thought the restaurant should have known better.    Moreover,   I would say that the satay served at Rise was of the worst I 've tasted offered by any restaurants in any hotel.      This is definitely does not live up to an MBS standard and reputation.      The dinner at Rise was the only bad experience we had during our short staycation.  It kinds of spoilt our dinner on the second night of our stay.    Would we stay again?  We would love to experience the club lounge at the Marina Bay Sands Singapore.   I want to believe it is going to be of a standard above the rest. But we 'll probably never going to step into Rise again.\n",
      "\n",
      "\n",
      " Text input: Military precision operation with hearts and soul - something other city hotels can learn from.    Making up for the lack of historical legacy and geographical location, MBS boasts of grandiose in its unique architectural style and all-hands-on-deck service that is uniquely Singapore.    Few hotels in the can match the breathtaking panorama from the 2000+ guest rooms. My advice is to opt for one with a city view.     Rooms are impeccably appointed and cleaned.  Mine ($500 per night) is humongous with two very huge independently controlled LCD TV.     Techies will like that the hotel system is linked to restaurants and brand-name shops across the MBS campus.      Foodies will appreciate the gastronomic experience of savoring the best of the best cuisines from traditional to fusion.    Families will love the diverse range of activities and options for everyone.     Last but not least, the tycoons will know that they will be accorded the VVVIP treatment even before they set foot here.    \n",
      "\n",
      "\n",
      " Text input: All these are good.   Transportation, location, ease of check-in, checkout, concierge, staff politeness, cleanliness, minibar items, distance to shopping mall/casino/restaurants, views from infinity pool and observation deck.     These can be improved   -I was not allowed to drink 'outside' drink at the infinity pool resting chair, but I brought that 'outside' drink from hotel's very own minibar in the room ud83e udd23 ud83e udd23 ud83d ude02    -Rise quality of breakfast can be further improved. The bacon in Western set was too hard. So as the youtiao in Chinese set. The congee, century egg, and soup based wonton Mee is bland. Finally the curry puff in malay set has too much curry powder taste.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing data\n",
    "print('\\n Text input: {}\\n'.format(X_trainset[0]))\n",
    "print('\\n Text input: {}\\n'.format(X_trainset[1]))\n",
    "print('\\n Text input: {}\\n'.format(X_trainset[2]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_string(s):\n",
    "    # Remove all non-word characters (everything except numbers and letters)\n",
    "    s = re.sub(r\"[^\\w\\s]\", '', s)\n",
    "    # Replace all runs of whitespaces with no space\n",
    "    s = re.sub(r\"\\s+\", '', s)\n",
    "    # replace digits with no space\n",
    "    s = re.sub(r\"\\d\", '', s)\n",
    "\n",
    "    return s\n",
    "\n",
    "def process_text(text):\n",
    "    \n",
    "    # Initialise\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    edited_stop_words = stopwords.words('english')\n",
    "    processed_text = \" \"\n",
    "    \n",
    "    # Process input\n",
    "    text_lower = text.lower()\n",
    "    word = word_tokenize(text_lower)\n",
    "    \n",
    "    # Alphabetical Tokens\n",
    "    alphabetic_tokens = [preprocess_string(word) for word in word if re.match('^[a-zA-Z]+$', word)]\n",
    "    \n",
    "    print(alphabetic_tokens)\n",
    "\n",
    "    # Edit stopwords list\n",
    "    edited_stop_words.remove('no')\n",
    "    edited_stop_words.remove('not')\n",
    "    edited_stop_words.remove(\"wouldn't\")\n",
    "    edited_stop_words.remove('wouldn')\n",
    "    edited_stop_words.remove(\"couldn't\")\n",
    "    edited_stop_words.remove('couldn')\n",
    "    edited_stop_words.remove(\"against\")\n",
    "    \n",
    "    # Remove stopwords from text and lemmatize\n",
    "    stop_words = set(edited_stop_words)\n",
    "    \n",
    "    lem_words = []\n",
    "    for word in alphabetic_tokens:\n",
    "        if word not in stop_words:\n",
    "            lem_words.append(lemmatizer.lemmatize(word))\n",
    "    \n",
    "    # Join the list of words\n",
    "    processed_text = processed_text.join(lem_words)     #print(edited_stop_words)\n",
    "\n",
    "    return processed_text\n",
    "\n",
    "def tokenize(x_train, x_test, x_val):\n",
    "    word_list = []\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    for sent in x_train:\n",
    "        # print(type(sent)) 'str'\n",
    "        for word in sent.lower().split():\n",
    "            word = preprocess_string(word)\n",
    "            if word not in stop_words and word != '':\n",
    "                word_list.append(word)\n",
    "\n",
    "    corpus = Counter(word_list)\n",
    "    # sorting on the basis of 1000 most common words.\n",
    "    corpus_ = sorted(corpus,key=corpus.get,reverse=True)[:1000]\n",
    "    # creating a dict\n",
    "    onehot_dict = {w:i+1 for i,w in enumerate(corpus_)}\n",
    "\n",
    "    # tokenize\n",
    "    final_list_train, final_list_test, final_list_val = [], [], []\n",
    "    for sent in x_train:\n",
    "            final_list_train.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split()\n",
    "                                     if preprocess_string(word) in onehot_dict.keys()])\n",
    "    for sent in x_test:\n",
    "            final_list_test.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split()\n",
    "                                    if preprocess_string(word) in onehot_dict.keys()])\n",
    "            \n",
    "    for sent in x_val:\n",
    "            final_list_val.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split()\n",
    "                                    if preprocess_string(word) in onehot_dict.keys()])\n",
    "\n",
    "    return np.array(final_list_train, dtype=object), np.array(final_list_test, dtype=object), np.array(final_list_val, dtype=object), onehot_dict\n",
    "\n",
    "X_train, X_test, X_val , vocab = tokenize(X_trainset, X_testset, X_valset)\n",
    "y_train, y_test, y_val = y_trainset, y_testset, y_valset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysing and visualising the length of the preprocessed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    10045.000000\n",
       "mean        55.226481\n",
       "std         49.119345\n",
       "min          1.000000\n",
       "25%         25.000000\n",
       "50%         40.000000\n",
       "75%         67.000000\n",
       "max        994.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_len = [len(i) for i in X_train]\n",
    "pd.Series(rev_len).hist(bins=15, edgecolor=\"red\")\n",
    "plt.show()\n",
    "pd.Series(rev_len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Text input: [254, 216, 571, 392, 7, 436, 497, 75, 186, 262, 21, 6, 33, 331, 446, 24, 48, 633, 51, 292, 853, 5, 46, 73, 254, 272, 331, 446, 156, 500, 116, 22, 41, 73, 446, 22, 41, 68, 859, 234, 272, 146, 112, 266, 16, 252, 5, 104, 232, 15, 16, 188, 201, 317, 112, 107, 5, 427, 446, 214, 41, 229, 46, 393, 177, 143, 902, 89, 568, 89, 15, 453, 98, 195, 197, 483, 446, 26, 69, 250, 143, 14, 603, 1, 189, 1, 30, 777, 591, 1, 85, 161, 498, 3, 85, 161, 498, 95, 201, 61, 120, 95, 161, 22, 3, 40, 3, 134, 175, 24, 3, 535, 102, 828, 130, 440, 116, 326, 547, 3, 873, 73, 46, 575, 551, 881, 547, 202, 664, 48, 374, 547, 24, 75, 67, 46, 29, 67, 556, 156, 103, 326, 89, 435, 9, 146, 446, 254, 869, 273, 37, 93, 73, 360, 23, 241, 447, 9, 3, 829, 505, 343, 120, 192, 231, 48, 584, 231, 107, 2, 194, 48, 18, 80, 44, 158, 870, 514, 261, 435, 5, 304, 138, 21, 478, 279, 126, 117, 57, 52, 683, 43, 103, 23, 261, 333, 569, 3, 210, 377, 16, 99, 320, 46, 784, 403, 16, 296, 268, 23, 371, 111, 285, 93, 269, 15, 34, 99, 931, 95, 30, 140, 111, 640, 269, 15, 497, 239, 166, 11, 705, 50, 972, 326, 43, 111, 16, 629, 174, 598, 25, 493, 219, 846, 50, 199, 326, 111, 103, 16, 127, 598, 371, 809, 353, 52, 1, 63, 750, 46, 303, 268, 371, 321, 23, 341, 446, 268, 331, 13, 5, 16, 5, 16, 226, 23, 41, 153, 21, 6, 33, 7, 105, 616, 146, 303, 428, 252, 167, 146, 371]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n Text input: {}\\n'.format(X_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Padding**\n",
    "\n",
    "To ensure uniform sequence length for batch processing, we pad the text. There needs to be a fixed input length for the tokens however, our data will not coincidentally have all of the same length. Therfore to solve this issue we will pad tokens at the end of shorter input sequences, ensuring they all have the same input length.\n",
    "\n",
    "This allows multiple sequences to be placed in a batch and efficiently processed in parallel since they have the same length. During model processing, it learns to ignore padding tokens and focus only on the meaningful input tokens, thus not being affected by the padding.\n",
    "\n",
    "We perform padding on the X values in the training, testing and validation data set. Since most reviews have a length of below 500, we will only consider sentences below the 500 range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "def padding_(sentences, seq_len):\n",
    "    features = np.zeros((len(sentences), seq_len), dtype=int)\n",
    "    for ii, review in enumerate(sentences):\n",
    "        if len(review) != 0:\n",
    "            features[ii, -len(review):] = np.array(review)[:seq_len]\n",
    "    return features\n",
    "\n",
    "\n",
    "X_train_pad = padding_(X_train, 500)\n",
    "X_test_pad = padding_(X_test, 500)\n",
    "X_val_pad = padding_(X_val, 500)\n",
    "\n",
    "# \n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_res, y_train_res = ros.fit_resample(X_train_pad, y_train)\n",
    "\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({1: 9670, 0: 9670})\n"
     ]
    }
   ],
   "source": [
    "# Check dataset proportion\n",
    "print('Resampled dataset shape %s' % Counter(y_train_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(torch.from_numpy(X_train_res), torch.from_numpy(y_train_res))\n",
    "test_data = TensorDataset(torch.from_numpy(X_test_pad), torch.from_numpy(y_test))\n",
    "val_data = TensorDataset(torch.from_numpy(X_val_pad), torch.from_numpy(y_val))\n",
    "\n",
    "# Batch size\n",
    "batch_size = 41\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "val_loader = DataLoader(val_data, shuffle=True, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([41, 500])\n",
      "Sample sentences x: \n",
      " tensor([[  0,   0,   0,  ..., 312, 346, 181],\n",
      "        [  0,   0,   0,  ..., 232,  35, 416],\n",
      "        [  0,   0,   0,  ..., 274,  52, 211],\n",
      "        ...,\n",
      "        [  0,   0,   0,  ..., 666,  80, 935],\n",
      "        [  0,   0,   0,  ..., 871,   1, 397],\n",
      "        [  0,   0,   0,  ..., 729,  42, 135]])\n",
      "Sample targets y: \n",
      " tensor([1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
      "        0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = next(dataiter)\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample sentences x: \\n', sample_x)\n",
    "print('Sample targets y: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentRNN(nn.Module):\n",
    "    def __init__(self, no_layers, vocab_size, hidden_dim, embedding_dim):\n",
    "        super(SentimentRNN,self).__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.no_layers = no_layers\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        # embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        #lstm\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_dim,\n",
    "                           num_layers=no_layers, batch_first=True)\n",
    "\n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        # linear and sigmoid layer\n",
    "        self.fc = nn.Linear(self.hidden_dim, output_dim)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self,x,hidden):\n",
    "        batch_size = x.size(0)\n",
    "        # embeddings and lstm_out\n",
    "\n",
    "        embeds = self.embedding(x)  # shape: B x S x Feature   since batch = True\n",
    "        #print(embeds.shape)  #[50, 500, 64]; 64 is the embedding_dim defined below.\n",
    "        \n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "\n",
    "        # Calling lstm_out.contiguous()to ensure the output tensor from the LSTM is contiguous before performing the view operation.\n",
    "        # reshapes the lstm_out tensor to have 2D layer with a shape of (batch_size * sequence_length, hidden_dim).\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "\n",
    "        # dropout and fully connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "\n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels, this is very important for an output of a sentiment score!!!\n",
    "\n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden\n",
    "\n",
    "\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        h0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
    "        c0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
    "        hidden = (h0,c0)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentRNN(\n",
      "  (embedding): Embedding(1001, 64)\n",
      "  (lstm): LSTM(64, 256, num_layers=2, batch_first=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "no_layers = 2\n",
    "vocab_size = len(vocab) + 1 #extra 1 for padding\n",
    "embedding_dim = 64\n",
    "output_dim = 1\n",
    "hidden_dim = 256\n",
    "\n",
    "\n",
    "model = SentimentRNN(no_layers, vocab_size, hidden_dim, embedding_dim)\n",
    "\n",
    "#moving to gpu\n",
    "model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# function to predict accuracy\n",
    "def acc(pred,label):\n",
    "    pred = torch.round(pred.squeeze())\n",
    "    return torch.sum(pred == label.squeeze()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the gradient clipping threshold and number of training epochs\n",
    "clip = 5\n",
    "epochs = 20\n",
    "\n",
    "# Initialize the minimum validation loss as positive infinity\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "epoch_tr_loss,epoch_vl_loss = [],[]\n",
    "epoch_tr_acc,epoch_vl_acc = [],[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_losses = []\n",
    "    train_acc = 0.0\n",
    "    # set the model to training mode\n",
    "    model.train()\n",
    "    # initialize hidden state\n",
    "    h = model.init_hidden(batch_size)\n",
    "    for inputs, labels in train_loader:\n",
    "\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        # Clear the gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # Perform a forward pass through the model\n",
    "        output,h = model(inputs,h)\n",
    "\n",
    "        # calculate the loss and perform backpropogation\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        # calculating accuracy\n",
    "        accuracy = acc(output,labels)\n",
    "        train_acc += accuracy\n",
    "        # Gradient Clipping: `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        # Optimizer Step: Update the model's parameters using the optimizer\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    # validation\n",
    "    # Set Model to Evaluation Mode\n",
    "    model.eval()\n",
    "    # Initialize Hidden States\n",
    "    val_h = model.init_hidden(batch_size)\n",
    "    val_losses = []\n",
    "    val_acc = 0.0\n",
    "    # Loop Through Test Data\n",
    "    for inputs, labels in val_loader:\n",
    "        val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # Forward Pass\n",
    "        output, val_h = model(inputs, val_h)\n",
    "\n",
    "        # Calculate Loss and Metrics(Accuracy)\n",
    "        val_loss = criterion(output.squeeze(), labels.float())\n",
    "        val_losses.append(val_loss.item())\n",
    "        accuracy = acc(output,labels)\n",
    "        val_acc += accuracy\n",
    "\n",
    "    epoch_train_loss = np.mean(train_losses)\n",
    "    epoch_val_loss = np.mean(val_losses)\n",
    "    # Aggregate Metrics\n",
    "    epoch_train_acc = train_acc/len(train_loader.dataset)\n",
    "    epoch_val_acc = val_acc/len(val_loader.dataset)\n",
    "    epoch_tr_loss.append(epoch_train_loss)\n",
    "    epoch_vl_loss.append(epoch_val_loss)\n",
    "    epoch_tr_acc.append(epoch_train_acc)\n",
    "    epoch_vl_acc.append(epoch_val_acc)\n",
    "    print(f'Epoch {epoch+1}')\n",
    "    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n",
    "    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n",
    "    print(25*'==')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'LSTM.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentRNN(\n",
       "  (embedding): Embedding(1001, 64)\n",
       "  (lstm): LSTM(64, 256, num_layers=2, batch_first=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SentimentRNN(no_layers, vocab_size, hidden_dim, embedding_dim)\n",
    "model.load_state_dict(torch.load('LSTM.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "test_accuracy : 93.76053962900505\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "# Initialize Hidden States\n",
    "test_h = model.init_hidden(batch_size)\n",
    "test_losses = []\n",
    "test_acc = 0.0\n",
    "output_total = []\n",
    "\n",
    "with torch.no_grad():\n",
    "# Loop Through Test Data\n",
    "        for inputs, labels in test_loader:\n",
    "                test_h = tuple([each.data for each in test_h])\n",
    "\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                # Forward Pass\n",
    "                output, test_h = model(inputs, test_h)\n",
    "\n",
    "                # Calculate Loss and Metrics(Accuracy)\n",
    "                test_loss = criterion(output.squeeze(), labels.float())\n",
    "                test_losses.append(test_loss.item())\n",
    "                accuracy = acc(output,labels)\n",
    "                test_acc += accuracy\n",
    "\n",
    "print(25*'==')\n",
    "print(f'test_accuracy : {test_acc/len(test_loader.dataset)*100}')\n",
    "print(25*'==')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
