{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/joelleng/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/joelleng/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/joelleng/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/joelleng/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import for database connection and other basic libraries\n",
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Import libraries for LSTM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to data warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwh_host = os.getenv(\"DATAWH_ENDPOINT\")\n",
    "dwh_user = os.getenv(\"DATAWH_USERNAME\")\n",
    "dwh_pw = os.getenv(\"DATAWH_PASSWORD\")\n",
    "dwh_name = os.getenv(\"DATAWH_NAME\")\n",
    "dwh_port = os.getenv(\"DATAWH_PORT\")\n",
    "\n",
    "# db_datawarehouse = mysql.connector.connect(\n",
    "#     host=dwh_host,\n",
    "#     user=dwh_user,\n",
    "#     passwd=dwh_pw,\n",
    "#     database=dwh_name\n",
    "# )\n",
    "\n",
    "engine = create_engine(f'mysql://{dwh_user}:{dwh_pw}@{dwh_host}:{dwh_port}/{dwh_name}', echo=False, future=True)\n",
    "db_datawarehouse = engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up for LSTM\n",
    "1) CUDA usage\n",
    "2) Load dataset and to train test split\n",
    "    - Utilise the temporal dimension of our data to conduct dataset splot, we will split it into 80/10/10 of train set, test set and val set respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_table('review', db_datawarehouse).copy()\n",
    "df2 = pd.read_sql_table('fact', db_datawarehouse).copy()\n",
    "df3 = pd.read_sql_table('time', db_datawarehouse).copy()\n",
    "df, df2, df3 = df.drop(columns=['index']), df2.drop(columns=['index']), df3.drop(columns=['index'])\n",
    "df4 = pd.merge(df, df2, on='ReviewID', how='inner')\n",
    "final_df = pd.merge(df4, df3, on='TimeID', how='inner')\n",
    "#print([data['Rating'].value_counts(), data['Text_Sentiment'].value_counts(), data['Title_Sentiment'].value_counts()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data is (10045,) and (10045,)\n",
      "Shape of test data is (593,) and (593,)\n",
      "Shape of val data is (594,) and (594,)\n"
     ]
    }
   ],
   "source": [
    "# Split into train, test, val set\n",
    "data = final_df[['CleanReviewText', 'StayDateYear', 'Text_Sentiment']]\n",
    "train_data = data[data['StayDateYear'].apply(lambda x: int(x)) < 2022]\n",
    "test_data = data[data['StayDateYear'].apply(lambda x: int(x)) >= 2022]\n",
    "X_trainset, y_trainset = train_data['CleanReviewText'].values, train_data['Text_Sentiment'].values\n",
    "X_test_val, y_test_val = test_data['CleanReviewText'].values, test_data['Text_Sentiment'].values\n",
    "X_testset, X_valset, y_testset, y_valset = train_test_split(X_test_val, y_test_val, test_size=0.5)\n",
    "\n",
    "print(f'Shape of train data is {X_trainset.shape} and {y_trainset.shape}')\n",
    "print(f'Shape of test data is {X_testset.shape} and {y_testset.shape}')\n",
    "print(f'Shape of val data is {X_valset.shape} and {y_valset.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Text input: due pandemic fluid nature border restriction opted spend anniversary year singapore opted separate staycations order compare hotel chosen duration staycations duration day different week marina bay sand second staycation stayed memory become fuzzy could remember restroom huge actually plan stay mb however due availability promotion decided second staycation boy glad always opt room club benefit however period staycation room club access renovation suite available decided going suite since would probably stay bed whole time would able justify hefty cost extra space suite hence trepidation booked stay december wife apprehensive prospect staycation without club benefit wanted cancel pro mb make full use technology prior received link select preferred time totally removed need speak front desk start staycation also got book slot use infinity pool hotel facility hotel really serious safe management measure hotel check every guest us lift room check every guest exit lift way extra make way guest room room work fantastically well room chilled level liking although stayed ordinary room mini bar replenished daily free treat always thought tv room silly idea however mb managed change opinion mine smart tv easy connect phone could watch netflix tv stayed hotel smart tv impossible connect staying mb like staying home better initial thought process one going spoil staycation due sheer number people lobby however personal experience super pleasant one ushered room seat attended thorough professional m adilah m adilah ask question filler make small talk asked question could provide solution example asked booked pool session told could get timing first day took trouble secure slot making check checking process set tone stay thank m adilah lot marina shoppes membership upgraded next tier made shopping dinning restaurant linked via escalator even better experience checking equally efficient form queue drop room card done con normally would long list con mb negative point would give unfortunate dinner experience rise restaurant located lobby waiting time food unduly long taste way fried rice satay mediocre really think restaurant justify waiting time plate fried rice stick satay moreover order satay came undercooked mutton impossible chew meat red bloody spit informed wait staff remaining stick satay sent back kitchen returned charred inedible hindsight thought even regular restaurant would prepared another stick satay served u instead taking undercooked one back kitchen char given current pandemic situation thought restaurant known better moreover would say satay served rise worst tasted offered restaurant hotel definitely live mb standard reputation dinner rise bad experience short staycation kind spoilt dinner second night stay would stay would love experience club lounge marina bay sand singapore want believe going standard rest probably never going step rise\n",
      "\n",
      "\n",
      " Text input: military precision operation heart soul something city hotel learn making lack historical legacy geographical location mb boast grandiose unique architectural style service uniquely singapore hotel match breathtaking panorama guest room advice opt one city view room impeccably appointed cleaned mine per night humongous two huge independently controlled lcd tv techie like hotel system linked restaurant shop across mb campus foodie appreciate gastronomic experience savoring best best cuisine traditional fusion family love diverse range activity option everyone last least tycoon know accorded vvvip treatment even set foot\n",
      "\n",
      "\n",
      " Text input: good transportation location ease checkout concierge staff politeness cleanliness minibar item distance shopping view infinity pool observation deck improved allowed drink drink infinity pool resting chair brought drink hotel minibar room quality breakfast improved bacon western set hard youtiao chinese set congee century egg soup based wonton mee bland finally curry puff malay set much curry powder taste\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing data\n",
    "print('\\n Text input: {}\\n'.format(X_trainset[0]))\n",
    "print('\\n Text input: {}\\n'.format(X_trainset[1]))\n",
    "print('\\n Text input: {}\\n'.format(X_trainset[2]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_string(s):\n",
    "    # Remove all non-word characters (everything except numbers and letters)\n",
    "    s = re.sub(r\"[^\\w\\s]\", '', s)\n",
    "    # Replace all runs of whitespaces with no space\n",
    "    s = re.sub(r\"\\s+\", '', s)\n",
    "    # replace digits with no space\n",
    "    s = re.sub(r\"\\d\", '', s)\n",
    "\n",
    "    return s\n",
    "\n",
    "def process_text(text):\n",
    "    \n",
    "    # Initialise\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    edited_stop_words = stopwords.words('english')\n",
    "    processed_text = \" \"\n",
    "    \n",
    "    # Process input\n",
    "    text_lower = text.lower()\n",
    "    word = word_tokenize(text_lower)\n",
    "    \n",
    "    # Alphabetical Tokens\n",
    "    alphabetic_tokens = [preprocess_string(word) for word in word if re.match('^[a-zA-Z]+$', word)]\n",
    "    \n",
    "    print(alphabetic_tokens)\n",
    "\n",
    "    # Edit stopwords list\n",
    "    edited_stop_words.remove('no')\n",
    "    edited_stop_words.remove('not')\n",
    "    edited_stop_words.remove(\"wouldn't\")\n",
    "    edited_stop_words.remove('wouldn')\n",
    "    edited_stop_words.remove(\"couldn't\")\n",
    "    edited_stop_words.remove('couldn')\n",
    "    edited_stop_words.remove(\"against\")\n",
    "    \n",
    "    # Remove stopwords from text and lemmatize\n",
    "    stop_words = set(edited_stop_words)\n",
    "    \n",
    "    lem_words = []\n",
    "    for word in alphabetic_tokens:\n",
    "        if word not in stop_words:\n",
    "            lem_words.append(lemmatizer.lemmatize(word))\n",
    "    \n",
    "    # Join the list of words\n",
    "    processed_text = processed_text.join(lem_words)     #print(edited_stop_words)\n",
    "\n",
    "    return processed_text\n",
    "\n",
    "def tokenize(x_train, x_test, x_val):\n",
    "    word_list = []\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    for sent in x_train:\n",
    "        # print(type(sent)) 'str'\n",
    "        for word in sent.lower().split():\n",
    "            word = preprocess_string(word)\n",
    "            if word not in stop_words and word != '':\n",
    "                word_list.append(word)\n",
    "\n",
    "    corpus = Counter(word_list)\n",
    "    # sorting on the basis of 1000 most common words.\n",
    "    corpus_ = sorted(corpus,key=corpus.get,reverse=True)[:1000]\n",
    "    # creating a dict\n",
    "    onehot_dict = {w:i+1 for i,w in enumerate(corpus_)}\n",
    "\n",
    "    # tokenize\n",
    "    final_list_train, final_list_test, final_list_val = [], [], []\n",
    "    for sent in x_train:\n",
    "            final_list_train.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split()\n",
    "                                     if preprocess_string(word) in onehot_dict.keys()])\n",
    "    for sent in x_test:\n",
    "            final_list_test.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split()\n",
    "                                    if preprocess_string(word) in onehot_dict.keys()])\n",
    "            \n",
    "    for sent in x_val:\n",
    "            final_list_val.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split()\n",
    "                                    if preprocess_string(word) in onehot_dict.keys()])\n",
    "\n",
    "    return np.array(final_list_train, dtype=object), np.array(final_list_test, dtype=object), np.array(final_list_val, dtype=object), onehot_dict\n",
    "\n",
    "X_train, X_test, X_val , vocab = tokenize(X_trainset, X_testset, X_valset)\n",
    "y_train, y_test, y_val = y_trainset, y_testset, y_valset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysing and visualising the length of the preprocessed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    10045.000000\n",
       "mean        55.824092\n",
       "std         49.515146\n",
       "min          1.000000\n",
       "25%         25.000000\n",
       "50%         40.000000\n",
       "75%         68.000000\n",
       "max       1035.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_len = [len(i) for i in X_train]\n",
    "pd.Series(rev_len).hist(bins=15, edgecolor=\"red\")\n",
    "plt.show()\n",
    "pd.Series(rev_len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Text input: [247, 213, 539, 205, 8, 426, 424, 1, 30, 260, 363, 21, 6, 33, 307, 448, 25, 885, 44, 596, 50, 297, 729, 5, 48, 78, 247, 272, 307, 448, 950, 474, 114, 2, 45, 78, 942, 448, 2, 45, 72, 92, 224, 272, 142, 92, 261, 16, 245, 5, 59, 223, 14, 16, 182, 293, 183, 299, 92, 107, 5, 396, 448, 208, 45, 221, 48, 80, 175, 139, 852, 535, 14, 440, 75, 188, 179, 402, 448, 26, 73, 241, 642, 139, 15, 3, 1, 160, 1, 31, 745, 560, 1, 20, 88, 42, 238, 2, 20, 88, 42, 238, 89, 183, 80, 89, 42, 2, 2, 280, 41, 2, 120, 172, 25, 2, 509, 63, 787, 127, 407, 114, 320, 498, 2, 793, 78, 48, 546, 482, 807, 498, 194, 550, 44, 357, 498, 25, 1, 498, 994, 71, 48, 28, 71, 522, 105, 320, 413, 9, 142, 448, 247, 827, 246, 38, 99, 78, 358, 23, 234, 439, 9, 2, 551, 476, 344, 861, 80, 184, 222, 861, 44, 561, 222, 107, 3, 187, 44, 18, 84, 30, 156, 642, 488, 20, 258, 413, 453, 5, 310, 65, 21, 460, 282, 125, 118, 56, 32, 638, 43, 105, 23, 258, 334, 136, 2, 152, 371, 781, 16, 104, 316, 781, 48, 614, 286, 16, 218, 262, 23, 365, 32, 287, 99, 266, 14, 35, 104, 746, 89, 31, 132, 32, 266, 14, 730, 424, 229, 994, 159, 12, 730, 660, 49, 913, 320, 43, 32, 16, 597, 169, 730, 568, 22, 468, 212, 9, 49, 195, 320, 32, 105, 16, 117, 568, 365, 772, 351, 32, 1, 67, 707, 48, 243, 262, 365, 322, 23, 329, 448, 274, 262, 307, 7, 5, 16, 5, 16, 210, 23, 45, 135, 21, 6, 33, 8, 95, 582, 142, 243, 414, 245, 164, 142, 899, 365]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n Text input: {}\\n'.format(X_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Padding**\n",
    "\n",
    "To ensure uniform sequence length for batch processing, we pad the text. There needs to be a fixed input length for the tokens however, our data will not coincidentally have all of the same length. Therfore to solve this issue we will pad tokens at the end of shorter input sequences, ensuring they all have the same input length.\n",
    "\n",
    "This allows multiple sequences to be placed in a batch and efficiently processed in parallel since they have the same length. During model processing, it learns to ignore padding tokens and focus only on the meaningful input tokens, thus not being affected by the padding.\n",
    "\n",
    "We perform padding on the X values in the training, testing and validation data set. Since most reviews have a length of below 500, we will only consider sentences below the 500 range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "def padding_(sentences, seq_len):\n",
    "    features = np.zeros((len(sentences), seq_len), dtype=int)\n",
    "    for ii, review in enumerate(sentences):\n",
    "        if len(review) != 0:\n",
    "            features[ii, -len(review):] = np.array(review)[:seq_len]\n",
    "    return features\n",
    "\n",
    "\n",
    "X_train_pad = padding_(X_train, 500)\n",
    "X_test_pad = padding_(X_test, 500)\n",
    "X_val_pad = padding_(X_val, 500)\n",
    "\n",
    "# \n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_res, y_train_res = ros.fit_resample(X_train_pad, y_train)\n",
    "\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({1: 9670, 0: 9670})\n",
      "Shape of train data is (19340, 500) and (19340,)\n"
     ]
    }
   ],
   "source": [
    "# Check dataset proportion\n",
    "print('Resampled dataset shape %s' % Counter(y_train_res))\n",
    "print(f'Shape of train data is {X_train_res.shape} and {y_train_res.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(torch.from_numpy(X_train_res), torch.from_numpy(y_train_res))\n",
    "test_data = TensorDataset(torch.from_numpy(X_test_pad), torch.from_numpy(y_test))\n",
    "val_data = TensorDataset(torch.from_numpy(X_val_pad), torch.from_numpy(y_val))\n",
    "\n",
    "# Batch size\n",
    "batch_size = 64\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "val_loader = DataLoader(val_data, shuffle=True, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([64, 500])\n",
      "Sample sentences x: \n",
      " tensor([[  0,   0,   0,  ...,  47,  14, 133],\n",
      "        [  0,   0,   0,  ..., 124,  23, 514],\n",
      "        [  0,   0,   0,  ..., 648, 420, 129],\n",
      "        ...,\n",
      "        [  0,   0,   0,  ..., 257,   1,  12],\n",
      "        [  0,   0,   0,  ..., 111, 201,  28],\n",
      "        [  0,   0,   0,  ..., 241,   1,   8]])\n",
      "Sample targets y: \n",
      " tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = next(dataiter)\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample sentences x: \\n', sample_x)\n",
    "print('Sample targets y: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentRNN(nn.Module):\n",
    "    def __init__(self, no_layers, vocab_size, hidden_dim, embedding_dim):\n",
    "        super(SentimentRNN,self).__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.no_layers = no_layers\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        # embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        #lstm\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_dim,\n",
    "                           num_layers=no_layers, batch_first=True)\n",
    "\n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        # linear and sigmoid layer\n",
    "        self.fc = nn.Linear(self.hidden_dim, output_dim)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self,x,hidden):\n",
    "        batch_size = x.size(0)\n",
    "        # embeddings and lstm_out\n",
    "\n",
    "        embeds = self.embedding(x)  # shape: B x S x Feature   since batch = True\n",
    "        #print(embeds.shape)  #[50, 500, 64]; 64 is the embedding_dim defined below.\n",
    "        \n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "\n",
    "        # Calling lstm_out.contiguous()to ensure the output tensor from the LSTM is contiguous before performing the view operation.\n",
    "        # reshapes the lstm_out tensor to have 2D layer with a shape of (batch_size * sequence_length, hidden_dim).\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "\n",
    "        # dropout and fully connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "\n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels, this is very important for an output of a sentiment score!!!\n",
    "\n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden\n",
    "\n",
    "\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        h0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
    "        c0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
    "        hidden = (h0,c0)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentRNN(\n",
      "  (embedding): Embedding(1001, 64)\n",
      "  (lstm): LSTM(64, 256, num_layers=2, batch_first=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "no_layers = 2\n",
    "vocab_size = len(vocab) + 1 #extra 1 for padding\n",
    "embedding_dim = 64\n",
    "output_dim = 1\n",
    "hidden_dim = 256\n",
    "\n",
    "\n",
    "model = SentimentRNN(no_layers, vocab_size, hidden_dim, embedding_dim)\n",
    "\n",
    "#moving to gpu\n",
    "model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# function to predict accuracy\n",
    "def acc(pred,label):\n",
    "    pred = torch.round(pred.squeeze())\n",
    "    return torch.sum(pred == label.squeeze()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "train_loss : 0.4544669097375791 val_loss : 0.22795734968450335\n",
      "train_accuracy : 75.84281282316442 val_accuracy : 87.7104377104377\n",
      "==================================================\n",
      "Epoch 2\n",
      "train_loss : 0.11992265978081781 val_loss : 0.222677451868852\n",
      "train_accuracy : 96.16339193381592 val_accuracy : 90.06734006734007\n",
      "==================================================\n",
      "Epoch 3\n",
      "train_loss : 0.054079242948047966 val_loss : 0.21449258592393664\n",
      "train_accuracy : 98.3971044467425 val_accuracy : 91.41414141414141\n",
      "==================================================\n",
      "Epoch 4\n",
      "train_loss : 0.024769165138953015 val_loss : 0.20737479627132416\n",
      "train_accuracy : 99.26059979317476 val_accuracy : 92.76094276094277\n",
      "==================================================\n",
      "Epoch 5\n",
      "train_loss : 0.012291649700044531 val_loss : 0.25537418145621715\n",
      "train_accuracy : 99.64322647362978 val_accuracy : 93.26599326599326\n",
      "==================================================\n",
      "Epoch 6\n",
      "train_loss : 0.009665309748630077 val_loss : 0.36478154361248016\n",
      "train_accuracy : 99.6794208893485 val_accuracy : 87.03703703703704\n",
      "==================================================\n",
      "Epoch 7\n",
      "train_loss : 0.00884905321354321 val_loss : 0.2696978333923552\n",
      "train_accuracy : 99.69493278179938 val_accuracy : 92.25589225589226\n",
      "==================================================\n",
      "Epoch 8\n",
      "train_loss : 0.0021900040011548255 val_loss : 0.31795280385348534\n",
      "train_accuracy : 99.870734229576 val_accuracy : 91.75084175084174\n",
      "==================================================\n",
      "Epoch 9\n",
      "train_loss : 0.04352446100061654 val_loss : 0.28184274584054947\n",
      "train_accuracy : 99.02275077559463 val_accuracy : 92.76094276094277\n",
      "==================================================\n",
      "Epoch 10\n",
      "train_loss : 0.0045434672539453914 val_loss : 0.2948167509360549\n",
      "train_accuracy : 99.81385729058945 val_accuracy : 92.42424242424242\n",
      "==================================================\n",
      "Epoch 11\n",
      "train_loss : 0.0004931271250162829 val_loss : 0.3088431515627437\n",
      "train_accuracy : 99.92761116856256 val_accuracy : 92.5925925925926\n",
      "==================================================\n",
      "Epoch 12\n",
      "train_loss : 5.6474127975419326e-05 val_loss : 0.31565277507211753\n",
      "train_accuracy : 99.93795243019649 val_accuracy : 92.92929292929293\n",
      "==================================================\n",
      "Epoch 13\n",
      "train_loss : 3.492063933663303e-05 val_loss : 0.3366958163678646\n",
      "train_accuracy : 99.93795243019649 val_accuracy : 92.92929292929293\n",
      "==================================================\n",
      "Epoch 14\n",
      "train_loss : 2.215105440647423e-05 val_loss : 0.3614022160569827\n",
      "train_accuracy : 99.93795243019649 val_accuracy : 92.76094276094277\n",
      "==================================================\n",
      "Epoch 15\n",
      "train_loss : 1.617665531366041e-05 val_loss : 0.34953622450767496\n",
      "train_accuracy : 99.93795243019649 val_accuracy : 93.0976430976431\n",
      "==================================================\n",
      "Epoch 16\n",
      "train_loss : 1.2651757554564353e-05 val_loss : 0.3827890575759941\n",
      "train_accuracy : 99.93795243019649 val_accuracy : 92.92929292929293\n",
      "==================================================\n",
      "Epoch 17\n",
      "train_loss : 9.22406702436592e-06 val_loss : 0.3705433480855491\n",
      "train_accuracy : 99.93795243019649 val_accuracy : 93.0976430976431\n",
      "==================================================\n",
      "Epoch 18\n",
      "train_loss : 7.2101909282290285e-06 val_loss : 0.3847650918695662\n",
      "train_accuracy : 99.93795243019649 val_accuracy : 92.92929292929293\n",
      "==================================================\n",
      "Epoch 19\n",
      "train_loss : 5.4134664413514285e-06 val_loss : 0.40818127632761997\n",
      "train_accuracy : 99.93795243019649 val_accuracy : 93.0976430976431\n",
      "==================================================\n",
      "Epoch 20\n",
      "train_loss : 4.495465026328574e-06 val_loss : 0.4182892417561056\n",
      "train_accuracy : 99.93795243019649 val_accuracy : 93.0976430976431\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# set the gradient clipping threshold and number of training epochs\n",
    "clip = 5\n",
    "epochs = 5\n",
    "\n",
    "# Initialize the minimum validation loss as positive infinity\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "epoch_tr_loss,epoch_vl_loss = [],[]\n",
    "epoch_tr_acc,epoch_vl_acc = [],[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_losses = []\n",
    "    train_acc = 0.0\n",
    "    # set the model to training mode\n",
    "    model.train()\n",
    "    # initialize hidden state\n",
    "    h = model.init_hidden(batch_size)\n",
    "    for inputs, labels in train_loader:\n",
    "\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        # Clear the gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # Perform a forward pass through the model\n",
    "        output,h = model(inputs,h)\n",
    "\n",
    "        # calculate the loss and perform backpropogation\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        # calculating accuracy\n",
    "        accuracy = acc(output,labels)\n",
    "        train_acc += accuracy\n",
    "        # Gradient Clipping: `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        # Optimizer Step: Update the model's parameters using the optimizer\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    # validation\n",
    "    # Set Model to Evaluation Mode\n",
    "    model.eval()\n",
    "    # Initialize Hidden States\n",
    "    val_h = model.init_hidden(batch_size)\n",
    "    val_losses = []\n",
    "    val_acc = 0.0\n",
    "    # Loop Through Test Data\n",
    "    for inputs, labels in val_loader:\n",
    "        val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # Forward Pass\n",
    "        output, val_h = model(inputs, val_h)\n",
    "\n",
    "        # Calculate Loss and Metrics(Accuracy)\n",
    "        val_loss = criterion(output.squeeze(), labels.float())\n",
    "        val_losses.append(val_loss.item())\n",
    "        accuracy = acc(output,labels)\n",
    "        val_acc += accuracy\n",
    "\n",
    "    epoch_train_loss = np.mean(train_losses)\n",
    "    epoch_val_loss = np.mean(val_losses)\n",
    "    # Aggregate Metrics\n",
    "    epoch_train_acc = train_acc/len(train_loader.dataset)\n",
    "    epoch_val_acc = val_acc/len(val_loader.dataset)\n",
    "    epoch_tr_loss.append(epoch_train_loss)\n",
    "    epoch_vl_loss.append(epoch_val_loss)\n",
    "    epoch_tr_acc.append(epoch_train_acc)\n",
    "    epoch_vl_acc.append(epoch_val_acc)\n",
    "    print(f'Epoch {epoch+1}')\n",
    "    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n",
    "    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n",
    "    print(25*'==')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'LSTM.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SentimentRNN(no_layers, vocab_size, hidden_dim, embedding_dim)\n",
    "model.load_state_dict(torch.load('LSTM.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "test_accuracy : 93.76053962900505\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "# Initialize Hidden States\n",
    "test_h = model.init_hidden(batch_size)\n",
    "test_losses = []\n",
    "test_acc = 0.0\n",
    "output_total = []\n",
    "\n",
    "with torch.no_grad():\n",
    "# Loop Through Test Data\n",
    "        for inputs, labels in test_loader:\n",
    "                test_h = tuple([each.data for each in test_h])\n",
    "\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                # Forward Pass\n",
    "                output, test_h = model(inputs, test_h)\n",
    "\n",
    "                # Calculate Loss and Metrics(Accuracy)\n",
    "                test_loss = criterion(output.squeeze(), labels.float())\n",
    "                test_losses.append(test_loss.item())\n",
    "                accuracy = acc(output,labels)\n",
    "                test_acc += accuracy\n",
    "\n",
    "print(25*'==')\n",
    "print(f'test_accuracy : {test_acc/len(test_loader.dataset)*100}')\n",
    "print(25*'==')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
